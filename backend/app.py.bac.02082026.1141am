from fastapi import FastAPI, HTTPException, BackgroundTasks, File, UploadFile, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, HTMLResponse, JSONResponse
from fastapi.staticfiles import StaticFiles

import subprocess
import json
import os
import shlex
import re
import logging
import time
import threading
import tempfile
import shutil

from pathlib import Path
from datetime import datetime
from queue import Queue, Empty, PriorityQueue
from typing import Optional

import humanize
from mutagen import File as MutagenFile

from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

# ---------------------------------------------------------------------------
# APP SETUP
# ---------------------------------------------------------------------------

app = FastAPI(title="Beets Replacement API")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

app.mount("/static", StaticFiles(directory="/app/static"), name="static")

# ---------------------------------------------------------------------------
# CONFIG / PATHS
# ---------------------------------------------------------------------------

ALBUMS_FILE = "/data/albums.json"
RECENT_FILE = "/data/recent_albums.json"
REGEN_SCRIPT = "/app/scripts/regenerate_albums.py"
BEETS_CONFIG = "/config/config.yaml"
INDEX_HTML = "/app/static/index.html"

INBOX_PATH = Path("/music/inbox")
LIBRARY_PATH = Path("/music/library")

# Volumio Configuration
VOLUMIO_MUSIC_MOUNT = "INTERNAL"  # or "USB", "NAS", etc.
VOLUMIO_PLAYLIST_DIR = Path("/data/playlist")
VOLUMIO_URL = "http://volumio.local:3000"  # Fixed URL

INBOX_STATS_CACHE_SECONDS = 60
DEBOUNCE_INBOX = 60.0
DEBOUNCE_LIBRARY = 30.0
DEBOUNCE_COVER = 30.0
DEBOUNCE_LYRICS = 10.0

IMPORT_TIMEOUT = 3600
REGEN_TIMEOUT = 900

# Lyrics rate limiting
LYRICS_RATE_LIMIT = 10
LYRICS_RETRY_DELAY = 60
LYRICS_MAX_RETRIES = 3

logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s %(message)s")
logger = logging.getLogger("beets-replacement")

# ---------------------------------------------------------------------------
# GLOBAL STATE
# ---------------------------------------------------------------------------

stop_event = threading.Event()

inbox_stats_cache = None
inbox_stats_cache_time = None
inbox_stats_lock = threading.Lock()

# Queues
inbox_q = Queue()
lib_q = Queue()
cover_q = Queue()
lyrics_q = PriorityQueue()

# Locks
inbox_lock = threading.Lock()
lib_lock = threading.Lock()
cover_lock = threading.Lock()
lyrics_lock = threading.Lock()

# Dedup sets
inbox_queued = set()
lib_queued = set()
cover_queued = set()
lyrics_queued = set()

# Lyrics rate limiting
lyrics_request_times = []
lyrics_last_429 = None
lyrics_failed_tracks = {}

# Threads
inbox_thread = None
lib_thread = None
cover_thread = None
cleanup_thread = None
lyrics_thread = None

# Observers
inbox_observer = None
lib_observer = None
cover_observer = None

# Watcher logs
watcher_logs = []
watcher_logs_lock = threading.Lock()
MAX_WATCHER_LOGS = 100
last_log_id = 0

# ---------------------------------------------------------------------------
# WATCHER LOG UTILITIES
# ---------------------------------------------------------------------------

def add_watcher_log(level, message):
    """Add a log entry to the watcher logs"""
    global last_log_id
    with watcher_logs_lock:
        last_log_id += 1
        entry = {
            "id": last_log_id,
            "timestamp": datetime.now().isoformat(),
            "level": level,
            "message": message
        }
        watcher_logs.insert(0, entry)
        
        if len(watcher_logs) > MAX_WATCHER_LOGS:
            watcher_logs.pop()
        
        logger.info(f"[{level.upper()}] {message}")

def get_recent_logs(since_id=None, limit=50):
    """Get recent logs, optionally since a specific ID"""
    with watcher_logs_lock:
        if since_id is None:
            return watcher_logs[:limit]
        else:
            return [log for log in watcher_logs if log["id"] > since_id][:limit]

# ---------------------------------------------------------------------------
# UTILITIES
# ---------------------------------------------------------------------------

def run_cmd_list(cmd, timeout=300):
    try:
        p = subprocess.run(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            timeout=timeout,
        )
        return p.returncode == 0, p.stdout or ""
    except Exception as e:
        return False, str(e)

def invalidate_inbox_cache(*_a, **_k):
    """Invalidate the inbox cache"""
    global inbox_stats_cache, inbox_stats_cache_time
    with inbox_stats_lock:
        if inbox_stats_cache is not None:
            inbox_stats_cache = None
            inbox_stats_cache_time = None

# ---------------------------------------------------------------------------
# VOLUMIO PLAYLIST UTILITIES
# ---------------------------------------------------------------------------

def convert_path_to_volumio_uri(beets_path: str) -> str:
    """
    Convert Beets library path to Volumio URI format
    
    Example:
        /music/library/Pink Floyd/Dark Side/Time.flac
        ? music-library/INTERNAL/Pink Floyd/Dark Side/Time.flac
    """
    # Remove /music/library prefix
    if beets_path.startswith("/music/library/"):
        relative_path = beets_path[len("/music/library/"):]
    elif beets_path.startswith("music/library/"):
        relative_path = beets_path[len("music/library/"):]
    else:
        relative_path = beets_path
    
    # Build Volumio URI
    volumio_uri = f"music-library/{VOLUMIO_MUSIC_MOUNT}/{relative_path}"
    
    return volumio_uri

# ---------------------------------------------------------------------------
# LYRICS UTILITIES
# ---------------------------------------------------------------------------

def can_make_lyrics_request():
    """Check if we can make a lyrics request based on rate limiting"""
    global lyrics_request_times, lyrics_last_429
    
    now = time.time()
    
    if lyrics_last_429 and (now - lyrics_last_429) < LYRICS_RETRY_DELAY:
        return False
    
    lyrics_request_times = [t for t in lyrics_request_times if now - t < 60]
    
    return len(lyrics_request_times) < LYRICS_RATE_LIMIT

def record_lyrics_request():
    """Record a lyrics request for rate limiting"""
    lyrics_request_times.append(time.time())

def record_lyrics_429():
    """Record that we got a 429 error"""
    global lyrics_last_429
    lyrics_last_429 = time.time()
    add_watcher_log("warning", f"Lyrics API rate limit hit, pausing for {LYRICS_RETRY_DELAY}s")

def check_track_has_lyrics(track_path):
    """Check if a track already has lyrics embedded"""
    try:
        audio = MutagenFile(track_path)
        if audio is None:
            return False
        
        lyrics_tags = ['lyrics', 'LYRICS', 'unsyncedlyrics', 'USLT', 'USLT:XXX:eng']
        for tag in lyrics_tags:
            if tag in audio and audio[tag]:
                return True
        
        return False
    except Exception as e:
        logger.debug(f"Error checking lyrics for {track_path}: {e}")
        return False

def get_tracks_without_lyrics(directory):
    """Get all audio tracks in a directory that don't have lyrics"""
    AUDIO_EXTS = (".flac", ".mp3", ".wav", ".m4a", ".ogg")
    tracks_without_lyrics = []
    
    try:
        for file in Path(directory).rglob("*"):
            if file.suffix.lower() in AUDIO_EXTS:
                if not check_track_has_lyrics(str(file)):
                    tracks_without_lyrics.append(str(file))
    except Exception as e:
        logger.error(f"Error scanning directory for lyrics: {e}")
    
    return tracks_without_lyrics

# ---------------------------------------------------------------------------
# INBOX CLEANUP
# ---------------------------------------------------------------------------

def cleanup_inbox_empty_dirs():
    """Remove directories that have no audio files"""
    AUDIO_EXTS = (".flac", ".mp3", ".wav", ".aac", ".m4a", ".ogg")
    
    def has_audio_files(directory):
        try:
            for root, dirs, files in os.walk(directory):
                if any(f.lower().endswith(AUDIO_EXTS) for f in files):
                    return True
            return False
        except Exception:
            return True
    
    def remove_empty_dirs(directory):
        if not directory.exists() or not directory.is_dir():
            return
        
        for subdir in list(directory.iterdir()):
            if subdir.is_dir():
                remove_empty_dirs(subdir)
        
        try:
            if not any(directory.iterdir()):
                add_watcher_log("info", f"Removing empty dir: {directory.name}")
                directory.rmdir()
        except Exception as e:
            logger.debug(f"[CLEANUP] Could not remove {directory}: {e}")
    
    if not INBOX_PATH.exists():
        return
    
    for item in INBOX_PATH.iterdir():
        if not item.is_dir() or item.name.startswith("."):
            continue
        
        if "unpack" in item.name.lower():
            continue
        
        if not has_audio_files(item):
            try:
                add_watcher_log("warning", f"Removing directory tree with no audio: {item.name}")
                shutil.rmtree(item)
            except Exception as e:
                logger.error(f"[CLEANUP] Failed to remove {item}: {e}")
        else:
            remove_empty_dirs(item)

def inbox_cleanup_scheduler():
    while not stop_event.is_set():
        try:
            cleanup_inbox_empty_dirs()
        except Exception:
            logger.exception("Inbox cleanup scheduler error")
        time.sleep(1800)

# ---------------------------------------------------------------------------
# STATIC FILE ROUTES
# ---------------------------------------------------------------------------

@app.get("/music/library/{full_path:path}", include_in_schema=False)
@app.head("/music/library/{full_path:path}", include_in_schema=False)
def serve_library_file(full_path: str):
    base = Path("/music/library")
    requested = (base / full_path).resolve()
    try:
        requested.relative_to(base)
    except ValueError:
        raise HTTPException(status_code=403, detail="Access denied")

    if requested.exists() and requested.is_file():
        return FileResponse(str(requested))
    raise HTTPException(status_code=404, detail="Not found")

@app.get("/placeholder.jpg", include_in_schema=False)
@app.head("/placeholder.jpg", include_in_schema=False)
def serve_placeholder():
    p = "/app/static/placeholder.jpg"
    if os.path.exists(p):
        return FileResponse(p, media_type="image/jpeg")
    raise HTTPException(status_code=404, detail="Not found")

# ---------------------------------------------------------------------------
# UI + JSON
# ---------------------------------------------------------------------------

@app.get("/", response_class=HTMLResponse)
def serve_index():
    if os.path.exists(INDEX_HTML):
        return FileResponse(INDEX_HTML, media_type="text/html")
    return HTMLResponse("<h1>Index not found</h1>", status_code=404)

@app.get("/data/albums.json")
def serve_albums_json():
    if os.path.exists(ALBUMS_FILE):
        return FileResponse(ALBUMS_FILE, media_type="application/json")
    return JSONResponse({"detail": "Not Found"}, status_code=404)

# ---------------------------------------------------------------------------
# PLAYLIST BUILDER API
# ---------------------------------------------------------------------------

@app.post("/api/playlist/build")
async def build_playlist(file: UploadFile = File(...)):
    """Build a Volumio playlist from a CSV file"""
    
    # Save uploaded CSV to temp file
    temp_csv = tempfile.NamedTemporaryFile(mode='wb', delete=False, suffix='.csv')
    try:
        shutil.copyfileobj(file.file, temp_csv)
        temp_csv.close()
        
        add_watcher_log("info", f"Building playlist from {file.filename}")
        
        # Run playlist builder script - capture stdout and stderr separately
        try:
            result = subprocess.run(
                ["python3", "/app/scripts/build_playlist.py", temp_csv.name],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                timeout=300
            )
            
            # Log the search progress from stderr
            if result.stderr:
                for line in result.stderr.splitlines()[:10]:  # Log first 10 lines
                    logger.debug(f"Playlist build: {line}")
            
            # Parse JSON from stdout only
            if result.returncode != 0:
                add_watcher_log("error", f"Playlist build failed: {result.stderr[:100]}")
                os.unlink(temp_csv.name)
                raise HTTPException(status_code=500, detail=f"Playlist build failed: {result.stderr}")
            
            playlist_data = json.loads(result.stdout)
            os.unlink(temp_csv.name)
            
            # Convert paths to Volumio URI format
            for track in playlist_data:
                if 'uri' in track:
                    track['uri'] = convert_path_to_volumio_uri(track['uri'])
                track['type'] = 'track'
                track['service'] = 'mpd'
            
            add_watcher_log("success", f"Playlist built: {len(playlist_data)} tracks")
            
            return {
                "status": "success",
                "tracks": len(playlist_data),
                "playlist": playlist_data
            }
            
        except json.JSONDecodeError as e:
            os.unlink(temp_csv.name)
            add_watcher_log("error", f"Invalid playlist JSON: {str(e)}")
            logger.error(f"JSON parse error. Output was: {result.stdout[:500]}")
            raise HTTPException(status_code=500, detail="Invalid playlist data returned")
            
    except Exception as e:
        if os.path.exists(temp_csv.name):
            os.unlink(temp_csv.name)
        add_watcher_log("error", f"Playlist build error: {str(e)[:100]}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/playlist/save")
async def save_playlist(
    playlist_name: str = Form(...),
    playlist_data: str = Form(...)
):
    """Save playlist in Volumio JSON format"""
    try:
        playlist = json.loads(playlist_data)
        
        # Ensure playlist directory exists
        VOLUMIO_PLAYLIST_DIR.mkdir(exist_ok=True, parents=True)
        
        # Create Volumio-compatible playlist file (.json, not .m3u!)
        playlist_file = VOLUMIO_PLAYLIST_DIR / f"{playlist_name}.json"
        
        # Ensure all tracks have required Volumio fields
        for i, track in enumerate(playlist):
            if 'service' not in track:
                track['service'] = 'mpd'
            if 'type' not in track:
                track['type'] = 'track'
            if 'tracknumber' not in track:
                track['tracknumber'] = i + 1
        
        # Save as JSON
        with open(playlist_file, 'w', encoding='utf-8') as f:
            json.dump(playlist, f, indent=2)
        
        add_watcher_log("success", f"Saved Volumio playlist: {playlist_name} ({len(playlist)} tracks)")
        
        return {
            "status": "success",
            "message": f"Playlist saved to {playlist_file}",
            "path": str(playlist_file),
            "tracks": len(playlist),
            "format": "Volumio JSON",
            "note": f"Playlist will appear in Volumio at {VOLUMIO_URL}"
        }
        
    except Exception as e:
        add_watcher_log("error", f"Failed to save playlist: {str(e)[:100]}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/playlist/list")
def list_playlists():
    """List all saved playlists"""
    try:
        if not VOLUMIO_PLAYLIST_DIR.exists():
            return {"playlists": []}
        
        playlists = []
        for file in VOLUMIO_PLAYLIST_DIR.glob("*.json"):
            try:
                with open(file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    playlists.append({
                        "name": file.stem,
                        "tracks": len(data) if isinstance(data, list) else 0,
                        "path": str(file)
                    })
            except Exception:
                continue
        
        return {"playlists": playlists}
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ---------------------------------------------------------------------------
# API ENDPOINTS
# ---------------------------------------------------------------------------

@app.get("/api/stats")
def stats():
    ok, out = run_cmd_list(["beet", "-c", BEETS_CONFIG, "stats"])
    if ok and out:
        tracks = albums = album_artists = 0
        total_time = total_size = "unknown"

        for line in out.splitlines():
            line = line.strip()
            if line.startswith("Tracks:"):
                tracks = int(line.split(":", 1)[1].strip() or 0)
            elif line.startswith("Albums:"):
                albums = int(line.split(":", 1)[1].strip() or 0)
            elif line.startswith("Album artists:"):
                album_artists = int(line.split(":", 1)[1].strip() or 0)
            elif line.startswith("Total time:"):
                total_time = line.split(":", 1)[1].strip()
            elif line.startswith("Approximate total size:"):
                total_size = line.split(":", 1)[1].strip()

        return {
            "tracks": tracks,
            "albums": albums,
            "album_artists": album_artists,
            "total_time": total_time,
            "total_size": total_size,
        }

    try:
        with open(ALBUMS_FILE, "r", encoding="utf-8") as f:
            data = json.load(f)
        return {
            "tracks": 0,
            "albums": len(data),
            "album_artists": len({a.get("albumartist") for a in data}),
            "total_time": "unknown",
            "total_size": "unknown",
        }
    except Exception:
        return {
            "tracks": 0,
            "albums": 0,
            "album_artists": 0,
            "total_time": "unknown",
            "total_size": "unknown",
        }

@app.post("/api/library/refresh")
def refresh_library():
    add_watcher_log("info", "Manual library refresh triggered")
    ok, out = run_cmd_list(["python3", REGEN_SCRIPT], timeout=120)
    if not ok:
        add_watcher_log("error", f"Library refresh failed: {out[:100]}")
        raise HTTPException(status_code=500, detail=out)
    add_watcher_log("success", "Library refresh completed")
    return {"status": "ok", "detail": out.strip()}

@app.post("/api/library/import")
def import_library(background_tasks: BackgroundTasks):
    args = ["beet", "-c", BEETS_CONFIG, "import", "-A", str(INBOX_PATH)]

    def run():
        add_watcher_log("info", "Manual import started")
        subprocess.run(args, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, timeout=IMPORT_TIMEOUT)
        add_watcher_log("success", "Manual import completed")

    background_tasks.add_task(run)
    return {"status": "started", "cmd": args}

@app.get("/api/albums")
def albums(limit: int = 5000):
    try:
        with open(ALBUMS_FILE, "r", encoding="utf-8") as f:
            return json.load(f)[:limit]
    except Exception:
        return []

@app.get("/api/albums/recent")
def recent(limit: int = 12):
    try:
        with open(RECENT_FILE, "r", encoding="utf-8") as f:
            return json.load(f)[:limit]
    except Exception:
        return []

# ---------------------------------------------------------------------------
# WATCHER STATUS API
# ---------------------------------------------------------------------------

@app.get("/api/watcher/status")
def watcher_status(since_id: int = None):
    """Get current watcher status and recent logs"""
    return {
        "inbox_queue": inbox_q.qsize(),
        "library_queue": lib_q.qsize(),
        "cover_queue": cover_q.qsize(),
        "lyrics_queue": lyrics_q.qsize(),
        "recent_logs": get_recent_logs(since_id=since_id)
    }

# ---------------------------------------------------------------------------
# LYRICS API
# ---------------------------------------------------------------------------

@app.get("/api/lyrics/stats")
def lyrics_stats():
    """Get lyrics fetching statistics"""
    with lyrics_lock:
        now = time.time()
        recent_requests = len([t for t in lyrics_request_times if now - t < 60])
        
        return {
            "queue_size": lyrics_q.qsize(),
            "requests_last_minute": recent_requests,
            "rate_limit": LYRICS_RATE_LIMIT,
            "paused_until": (lyrics_last_429 + LYRICS_RETRY_DELAY) if lyrics_last_429 else None,
            "failed_tracks": len(lyrics_failed_tracks)
        }

@app.post("/api/lyrics/scan")
def scan_for_missing_lyrics(background_tasks: BackgroundTasks):
    """Scan library for tracks missing lyrics and queue them"""
    def scan():
        add_watcher_log("info", "Starting library-wide lyrics scan")
        count = 0
        
        try:
            for album_dir in LIBRARY_PATH.iterdir():
                if not album_dir.is_dir() or album_dir.name.startswith("."):
                    continue
                
                tracks = get_tracks_without_lyrics(str(album_dir))
                for track in tracks:
                    with lyrics_lock:
                        if track not in lyrics_queued:
                            lyrics_queued.add(track)
                            lyrics_q.put((2, time.time(), track))
                            count += 1
            
            add_watcher_log("success", f"Lyrics scan complete: {count} tracks queued")
        except Exception as e:
            add_watcher_log("error", f"Lyrics scan failed: {str(e)[:100]}")
    
    background_tasks.add_task(scan)
    return {"status": "started"}

@app.post("/api/lyrics/pause")
def pause_lyrics_fetching():
    """Temporarily pause lyrics fetching"""
    global lyrics_last_429
    lyrics_last_429 = time.time()
    add_watcher_log("info", f"Lyrics fetching paused for {LYRICS_RETRY_DELAY}s")
    return {"status": "paused", "duration": LYRICS_RETRY_DELAY}

@app.post("/api/lyrics/resume")
def resume_lyrics_fetching():
    """Resume lyrics fetching"""
    global lyrics_last_429
    lyrics_last_429 = None
    add_watcher_log("info", "Lyrics fetching resumed")
    return {"status": "resumed"}

# ---------------------------------------------------------------------------
# INBOX API
# ---------------------------------------------------------------------------

@app.get("/api/inbox")
@app.get("/api/inbox/stats")
def get_inbox_stats():
    """Get inbox statistics with caching"""
    global inbox_stats_cache, inbox_stats_cache_time
    
    with inbox_stats_lock:
        now = datetime.now()
        if inbox_stats_cache and inbox_stats_cache_time:
            age = (now - inbox_stats_cache_time).total_seconds()
            if age < INBOX_STATS_CACHE_SECONDS:
                logger.debug(f"Returning cached inbox stats (age: {age:.1f}s)")
                return inbox_stats_cache

        logger.info("Computing fresh inbox stats")
        inbox_stats_cache = compute_inbox_stats_fast()
        inbox_stats_cache_time = now
        return inbox_stats_cache

def compute_inbox_stats_fast():
    """Compute inbox stats using shell commands"""
    
    if not INBOX_PATH.exists():
        logger.warning(f"Inbox path does not exist: {INBOX_PATH}")
        return {
            "tracks": 0,
            "total_time": "0 seconds",
            "total_size": "0 B",
            "artists": 0,
            "albums": 0,
            "album_artists": 0,
        }

    try:
        count_cmd = f'find "{INBOX_PATH}" -type f \\( -iname "*.mp3" -o -iname "*.flac" -o -iname "*.m4a" -o -iname "*.ogg" -o -iname "*.wav" -o -iname "*.aac" \\) | wc -l'
        result = subprocess.run(count_cmd, shell=True, capture_output=True, text=True, timeout=10)
        tracks = int(result.stdout.strip()) if result.returncode == 0 else 0
        
        size_cmd = f'du -sb "{INBOX_PATH}" 2>/dev/null | cut -f1'
        result = subprocess.run(size_cmd, shell=True, capture_output=True, text=True, timeout=10)
        total_bytes = int(result.stdout.strip()) if result.returncode == 0 else 0
        
        artists = set()
        albums = set()
        
        try:
            for item in list(INBOX_PATH.iterdir())[:200]:
                if not item.is_dir() or item.name.startswith(".") or "_UNPACK_" in item.name:
                    continue
                artists.add(item.name)
                albums.add(item.name)
        except Exception as e:
            logger.warning(f"Error sampling directories: {e}")
        
        estimated_minutes = tracks * 3
        time_str = humanize.precisedelta(estimated_minutes * 60) if estimated_minutes > 0 else "0 seconds"

        return {
            "tracks": tracks,
            "total_time": time_str,
            "total_size": humanize.naturalsize(total_bytes),
            "artists": len(artists),
            "albums": len(albums),
            "album_artists": len(artists),
        }
        
    except Exception as e:
        logger.error(f"Error computing inbox stats: {e}")
        return {
            "tracks": 0,
            "total_time": "error",
            "total_size": "0 B",
            "artists": 0,
            "albums": 0,
            "album_artists": 0,
        }

@app.get("/api/inbox/tree")
def inbox_tree():
    if not INBOX_PATH.exists():
        return {"folders": {}}
    return {
        "folders": {
            d.name: [x.name for x in d.iterdir() if x.is_dir()]
            for d in INBOX_PATH.iterdir()
            if d.is_dir()
        }
    }

@app.get("/api/inbox/folder")
def inbox_folder(artist: str, album: str):
    folder = INBOX_PATH / artist / album
    if not folder.exists() or not folder.is_dir():
        return {"files": []}
    return {"files": [f.name for f in folder.iterdir() if f.is_file()]}

# ---------------------------------------------------------------------------
# FILE WATCHER HANDLER
# ---------------------------------------------------------------------------

class DebouncedHandler(FileSystemEventHandler):
    def __init__(self, queue, lock, queued, debounce, label, root=None, ignore_dirs=None):
        self.queue = queue
        self.lock = lock
        self.queued = queued
        self.debounce = debounce
        self.label = label
        self.root = Path(root).resolve() if root else None
        self.ignore_dirs = ignore_dirs or []
        self.last_seen = {}

    def on_any_event(self, event):
        try:
            path = event.src_path
            target = path if os.path.isdir(path) else os.path.dirname(path)
            target = os.path.normpath(target)

            if self.root:
                try:
                    Path(target).resolve().relative_to(self.root)
                except ValueError:
                    return

            if self.ignore_dirs:
                path_parts = Path(target).parts
                for part in path_parts:
                    if any(part.startswith(x) for x in self.ignore_dirs):
                        return

            base = os.path.basename(target)
            if base.startswith(".") or base.startswith("~"):
                return

            now = time.time()
            with self.lock:
                if now - self.last_seen.get(target, 0) < self.debounce:
                    return
                self.last_seen[target] = now
                if target in self.queued:
                    return
                self.queued.add(target)

            add_watcher_log("info", f"{self.label}: {os.path.basename(target)}")
            self.queue.put(target)

        except Exception:
            logger.exception("%s handler error", self.label)

# ---------------------------------------------------------------------------
# WORKERS
# ---------------------------------------------------------------------------

def inbox_worker():
    logger.info("Inbox worker started")
    add_watcher_log("info", "Inbox worker started")
    while not stop_event.is_set():
        try:
            target = inbox_q.get(timeout=1)
        except Empty:
            continue

        with inbox_lock:
            inbox_queued.discard(target)

        try:
            time.sleep(DEBOUNCE_INBOX)
            if not os.path.isdir(target):
                continue

            args = ["beet", "-c", BEETS_CONFIG, "import", "-A", target]
            add_watcher_log("info", f"Importing: {os.path.basename(target)}")
            subprocess.run(args, timeout=IMPORT_TIMEOUT)

            invalidate_inbox_cache()
            add_watcher_log("success", f"Import complete: {os.path.basename(target)}")
            
            tracks = get_tracks_without_lyrics(target)
            if tracks:
                with lyrics_lock:
                    for track in tracks:
                        if track not in lyrics_queued:
                            lyrics_queued.add(track)
                            lyrics_q.put((1, time.time(), track))
                add_watcher_log("info", f"Queued {len(tracks)} tracks for lyrics")

        except Exception as e:
            add_watcher_log("error", f"Import failed: {str(e)[:50]}")
        finally:
            inbox_q.task_done()

def library_worker():
    logger.info("Library worker started")
    add_watcher_log("info", "Library worker started")
    while not stop_event.is_set():
        try:
            target = lib_q.get(timeout=1)
        except Empty:
            continue

        with lib_lock:
            lib_queued.discard(target)

        try:
            time.sleep(DEBOUNCE_LIBRARY)
            success = False

            ok, _ = run_cmd_list(["python3", REGEN_SCRIPT, target], timeout=REGEN_TIMEOUT)
            success = success or ok

            if not success:
                t2 = re.sub(r"\s*\[\d+\]$", "", target)
                if t2 != target and os.path.exists(t2):
                    ok, _ = run_cmd_list(["python3", REGEN_SCRIPT, t2], timeout=REGEN_TIMEOUT)
                    success = success or ok

            if not success:
                ok, _ = run_cmd_list(["python3", REGEN_SCRIPT], timeout=REGEN_TIMEOUT * 2)
                success = success or ok

            if success:
                add_watcher_log("success", f"Library updated: {os.path.basename(target)}")
                run_cmd_list(["python3", "/app/scripts/recompute_recent.py"], timeout=120)

        except Exception as e:
            add_watcher_log("error", f"Library update failed: {str(e)[:50]}")
        finally:
            lib_q.task_done()

def cover_worker():
    logger.info("Cover worker started")
    add_watcher_log("info", "Cover worker started")
    while not stop_event.is_set():
        try:
            target = cover_q.get(timeout=1)
        except Empty:
            continue

        with cover_lock:
            cover_queued.discard(target)

        try:
            album_dir = Path(target)
            cover = album_dir / "cover.jpg"

            if not album_dir.exists() or cover.exists():
                continue

            add_watcher_log("info", f"Fetching cover: {album_dir.name}")
            ok, _ = run_cmd_list(["python3", "/app/scripts/fetch_cover.py", str(album_dir)], timeout=300)

            if ok:
                add_watcher_log("success", f"Cover fetched: {album_dir.name}")
                run_cmd_list(["python3", REGEN_SCRIPT, str(album_dir)], timeout=REGEN_TIMEOUT)
                run_cmd_list(["python3", "/app/scripts/recompute_recent.py"], timeout=120)

        except Exception as e:
            add_watcher_log("error", f"Cover fetch error: {str(e)[:50]}")
        finally:
            cover_q.task_done()

def lyrics_worker():
    """Worker for fetching lyrics with rate limiting"""
    logger.info("Lyrics worker started")
    add_watcher_log("info", "Lyrics worker started")
    
    while not stop_event.is_set():
        try:
            if not can_make_lyrics_request():
                time.sleep(1)
                continue
            
            try:
                priority, timestamp, track_path = lyrics_q.get(timeout=1)
            except Empty:
                continue
            
            with lyrics_lock:
                lyrics_queued.discard(track_path)
            
            try:
                if not os.path.exists(track_path):
                    continue
                
                if check_track_has_lyrics(track_path):
                    continue
                
                retry_count = lyrics_failed_tracks.get(track_path, 0)
                if retry_count >= LYRICS_MAX_RETRIES:
                    continue
                
                time.sleep(DEBOUNCE_LYRICS)
                
                track_basename = os.path.basename(track_path)
                add_watcher_log("info", f"Fetching lyrics: {track_basename}")
                
                record_lyrics_request()
                
                args = ["beet", "-c", BEETS_CONFIG, "lyrics", "-f", track_path]
                ok, output = run_cmd_list(args, timeout=60)
                
                if "429" in output or "Too Many Requests" in output:
                    record_lyrics_429()
                    with lyrics_lock:
                        if track_path not in lyrics_queued:
                            lyrics_queued.add(track_path)
                            lyrics_q.put((priority + 1, time.time(), track_path))
                    lyrics_failed_tracks[track_path] = retry_count + 1
                    continue
                
                if ok or "lyrics found" in output.lower():
                    add_watcher_log("success", f"Lyrics found: {track_basename}")
                    lyrics_failed_tracks.pop(track_path, None)
                else:
                    if "not found" not in output.lower():
                        lyrics_failed_tracks[track_path] = retry_count + 1

            except Exception as e:
                logger.exception("Lyrics fetch failed")
                lyrics_failed_tracks[track_path] = lyrics_failed_tracks.get(track_path, 0) + 1
            finally:
                lyrics_q.task_done()
        
        except Exception as e:
            logger.exception("Lyrics worker error")
            time.sleep(5)

# ---------------------------------------------------------------------------
# FASTAPI LIFESPAN
# ---------------------------------------------------------------------------

@app.on_event("startup")
def startup():
    global inbox_thread, lib_thread, cover_thread, cleanup_thread, lyrics_thread
    global inbox_observer, lib_observer, cover_observer

    stop_event.clear()
    add_watcher_log("info", "Application starting up")

    inbox_thread = threading.Thread(target=inbox_worker, daemon=True)
    lib_thread = threading.Thread(target=library_worker, daemon=True)
    cover_thread = threading.Thread(target=cover_worker, daemon=True)
    cleanup_thread = threading.Thread(target=inbox_cleanup_scheduler, daemon=True)
    lyrics_thread = threading.Thread(target=lyrics_worker, daemon=True)

    inbox_thread.start()
    lib_thread.start()
    cover_thread.start()
    cleanup_thread.start()
    lyrics_thread.start()

    inbox_handler = DebouncedHandler(
        inbox_q, inbox_lock, inbox_queued, DEBOUNCE_INBOX, "INBOX",
        root=INBOX_PATH, ignore_dirs=["_UNPACK_", "UNPACK", "unpack"]
    )
    
    inbox_observer = Observer()
    inbox_observer.schedule(inbox_handler, str(INBOX_PATH), recursive=True)

    lib_observer = Observer()
    lib_observer.schedule(
        DebouncedHandler(lib_q, lib_lock, lib_queued, DEBOUNCE_LIBRARY, "LIBRARY", root=LIBRARY_PATH),
        str(LIBRARY_PATH), recursive=True
    )

    cover_observer = Observer()
    cover_observer.schedule(
        DebouncedHandler(cover_q, cover_lock, cover_queued, DEBOUNCE_COVER, "COVER", root=LIBRARY_PATH),
        str(LIBRARY_PATH), recursive=True
    )

    inbox_observer.start()
    lib_observer.start()
    cover_observer.start()

    add_watcher_log("success", "All workers and watchers started")
    logger.info("Startup complete")

@app.on_event("shutdown")
def shutdown():
    add_watcher_log("warning", "Application shutting down")
    stop_event.set()

    for obs in (inbox_observer, lib_observer, cover_observer):
        if obs:
            obs.stop()
            obs.join()

    logger.info("Shutdown complete")
